{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа №2. Часть 2\n",
    "### Полины Кудрявцевой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В прошлый дедлайн не успела доделать домашнее задание, поэтому в репозитории на всякий случай лежит обновленный вариант. В этой работе повторяю часть кода, где требуется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A Moveable Feast.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "words = [w for w in tokens if w.isalpha()]\n",
    "\n",
    "lemmas = []\n",
    "\n",
    "for i in words:\n",
    "    analise = morph.parse(i)\n",
    "    lemmas.append(analise)\n",
    "    \n",
    "forms_from_text = []\n",
    "for lemma in lemmas:\n",
    "    one = lemma[0]\n",
    "    form = [one.normal_form, one.tag.POS]\n",
    "    forms_from_text.append(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_of_verbs = collections.Counter()\n",
    "for i in forms_from_text:\n",
    "    if i[1] == 'VERB':\n",
    "        counter_of_verbs[i[0]] += 1\n",
    "\n",
    "top_of_verbs = counter_of_verbs.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i[0] for i in top_of_verbs[:20]]\n",
    "size = list([i[1] for i in top_of_verbs[:20]])\n",
    "colors = ['blue', 'lightcoral', 'red', 'green', 'mediumorchid', 'blueviolet', \n",
    "          'navy', 'royalblue', 'darkslategrey', 'limegreen', \n",
    "          'darkgreen', 'yellow', 'darkorange', 'orange', 'brown', 'pink', 'crimson', 'hotpink', 'coral', 'black']\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.title('Сравнительная статистика по ТОП-20 глаголам')\n",
    "plt.pie(size, colors=colors, startangle=180)\n",
    "plt.legend(labels, loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_of_adverbs = collections.Counter()\n",
    "for i in forms_from_text:\n",
    "    if i[1] == 'ADVB':\n",
    "        counter_of_adverbs[i[0]] += 1\n",
    "    \n",
    "top_of_adverbs = counter_of_adverbs.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adverbs = [i[0] for i in top_of_adverbs[:20]]\n",
    "frequency_of_adverbs = [i[1] for i in top_of_adverbs[:20]]\n",
    "\n",
    "plt.scatter(frequency_of_adverbs, adverbs, color='green')\n",
    "\n",
    "plt.title('Сравнительная статистика по ТОП-20 наречиям')\n",
    "plt.ylabel('Наречия')\n",
    "plt.xlabel('Количество вхождений наречий')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_of_forms = collections.Counter()\n",
    "allf = 0\n",
    "for i in forms_from_text:\n",
    "    allf = allf + 1\n",
    "    form = i[1]\n",
    "    counter_of_forms[form] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = ['NOUN', 'ADJF', 'ADVB', 'PREP', 'CONJ', 'None', 'PRTF', 'NPRO', 'VERB', \n",
    "     'PRCL', 'ADJS', 'INFN', 'NUMR', 'PRTS', 'COMP', 'GRND', 'PRED', 'INTJ']\n",
    "\n",
    "frequency_of_pos = ['0.216384778012685', '0.10066067653276956', '0.06477272727272727', '0.10005285412262156', \n",
    "                    '0.12579281183932348', '0.004492600422832981', '0.006474630021141649', '0.11265856236786469', \n",
    "                    '0.14756871035940802', '0.053091966173361524', '0.010835095137420718', '0.033298097251585626', \n",
    "                    '0.00412262156448203', '0.002536997885835095', '0.004968287526427062', '0.004386892177589852', \n",
    "                    '0.006448202959830867', '0.0014534883720930232']\n",
    "\n",
    "plt.bar(frequency_of_pos, pos, color='purple')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Частотность разных частей речи')\n",
    "plt.ylabel('Частотность')\n",
    "plt.xlabel('Части речи')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Создается список словарей, чтобы потом сделать датафрейм. Берутся только первые варианты разбора слов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
    "morph = MorphAnalyzer()\n",
    "morphs = []\n",
    "dic_for_dataframe = []\n",
    "for i in range(len(words)):\n",
    "    w = morph.parse(words[i])\n",
    "    morphs.append(w)\n",
    "    word = w[0]\n",
    "    dic_for_dataframe.append({'word': word.word,\n",
    "                      'normal_form': word.normal_form,\n",
    "                      'pos': word.tag.POS,\n",
    "                      'animacy': word.tag.animacy,\n",
    "                      'aspect': word.tag.aspect,\n",
    "                      'case': word.tag.case,\n",
    "                      'gender': word.tag.gender,\n",
    "                      'involvement': word.tag.involvement,\n",
    "                      'mood': word.tag.mood,\n",
    "                      'number': word.tag.number,\n",
    "                      'person': word.tag.person,\n",
    "                      'tense': word.tag.tense,\n",
    "                      'transitivity': word.tag.transitivity,\n",
    "                      'voice ': word.tag.voice\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic_for_dataframe).fillna('')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join([word for word in df['normal_form'].values])\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    background_color ='white',\n",
    "    width = 800,\n",
    "    height = 800, \n",
    ").generate(text)\n",
    "\n",
    "plt.figure(figsize = (9, 12), facecolor = None) \n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\") \n",
    "plt.title('Облако слов')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"Праздник, который всегда с тобой\" - это книга воспомнинаний, и в ней упоминаются многие литераторы того времени. Как видно в wordclaud'е, часто упоминается некий \"Скотт\" - это, как я понимаю, Френсис Скотт Фицджеральд. Поэтому в следующей иллюстрации его имя будет взято именно в таком варианте.\n",
    "\n",
    "* Берем некоторые имена литераторов, упоминающиеся в книге по информации из открытых источников (я сейчас не могу опираться на свои воспоминания об этой книге), и представляем частотность их употребления в виде Lexical Dispersion Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['скотт', 'достоевский', 'кроули', 'паунд', 'толстой']\n",
    "draw.dispersion.dispersion_plot(df['normal_form'], \n",
    "                                words, ignore_case=False, \n",
    "                                title=\"Lexical Dispersion Plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
